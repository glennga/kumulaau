\section{Parameter Estimation}\label{sec:pe}
In this section, we discuss our approach toward parameter estimation.
Specifically, we aim to address the problem of maximum likelihood.
Let $\mathcal{M} : \theta, V \mapsto \mathcal{D}'$ define a function that maps a parameter set $\theta$ and some
random variables $V$ to generated data $\mathcal{D}'$.
Given that $V$ is randomly distributed, $\mathcal{M}(\theta, V)$ may produce different $\mathcal{D}'$ for the same
parameter set $\theta$.
This means that our generated data set $\mathcal{D}'$ is also randomly distributed. % TODO: Expand here???
Given observations $\mathcal{D}$ and the property that both $\mathcal{D}$ \& $\mathcal{D}'$ are discrete,
the likelihood of parameters $\theta$ is the probability that our generated data
$\mathcal{D}'$ equals our observed data $\mathcal{D}$~\cite{liepeABCSysBioApproximateBayesian2010}.
\begin{equation}
    \mathcal{L}(\theta) = \Pr(\mathcal{D} = \mathcal{M}(\theta, V))
\end{equation}

If $\mathcal{L}$ is continuous, one technique to calculate a maximum likelihood for our parameters $\hat{\theta}$
involves finding the critical points of $\mathcal{L}$ (where $\frac{d\mathcal{L}}{d\theta} = 0$) and choosing the point
$\hat{\theta}$ with the largest value of $\mathcal{L}$.
There are however, several problems with this approach:
\begin{enumerate}
    \item This assumes that we can explicitly express $\mathcal{L}$.
        For simulator based $\mathcal{M}$ like ours, this is not trivial to do.
    \item $\theta$ may represent multiple parameters to differentiate over.
        Even if we could express our likelihood, calculating this multi-dimensional derivative analytically may be
        not feasible.
    \item With high dimensional data $\mathcal{D}$ and $\mathcal{D}'$, an exact match
        $\mathcal{D} = \mathcal{D}'$ may not occur within a reasonable amount of time.
\end{enumerate}
Consequently, we must look into other approaches to \textit{infer} $\mathcal{L}$.
The two problems this section aims to address are given below:
\begin{enumerate}
    \item How to efficiently compute $\mathcal{L}$ for a single $\theta$.
    \item How to infer $\mathcal{L}$ for all $\theta$.
\end{enumerate}

\subsection{Approximate Bayesian Computation}\label{subsec:abc}
In this section, we discuss an approximate method to compute the likelihood $\mathcal{L}$ for some parameter set $\theta$.

Let us start with a simple weighted coin model.
Let $\mathcal{M} : \mathbb{R} \mapsto \{ 0, 1 \}$



Let us start with a simple simulator based model $\mathcal{M}$ that accepts some parameter $\theta_1$ and outputs some
result $\mathcal{D}'_1$.
$\mathcal{D}'_1$

TODO: Mention how finding an exact match is near to impossible, briefly mention the use of summary statistics,
go over the approximate matches.

\subsubsection{Approximate Matches: $\epsilon$}

\subsection{Likelihood Estimation}\label{subsec:le}
We now know how to determine the likelihood of a single point in our parameter space.


\subsection{Markov Chain Monte Carlo}\label{subsec:mcmc}
In this section, we discuss the Markov Chain Monte Carlo (MCMC) approach to approximating a likelihood function.

\subsubsection{Monte Carlo}
In Bayesian inference, the characterization of the uncertainty of some parameter set given observations is given by
the posterior distribution below:
\begin{equation}
    \Pr(\theta \mid \mathcal{D}') \propto \mathcal{L}(\theta) p(\theta)
\end{equation}
where $p(\theta)$ represents our prior beliefs our the parameters~\cite{liepeABCSysBioApproximateBayesian2010}.

\subsubsection{Markov Chain}

\subsubsection{Metropolis Algorithm}
In this section, we describe the Metropolis algorithm-- an algorithm that can draw samples from \emph{any} probability
distribution.

\begin{algorithm}[t]
    \SetAlgoLined
    \DontPrintSemicolon
    \Fn{MetropolisSampler \ {$(T)$}} {
        \KwIn{an upward constant mutation bias $c$, downward linear mutation bias $d$, current repeat length $\ell$}
        \KwOut{a repeat length from the next generation $\ell_{t+1}$}
        $\ell_{t+1} \gets \ell_t$ \;
        \If{$c < \ \sim U(0, 1)$}{
            $\ell_{t+1} \gets \ell_{t+1} + 1$ \;
        }
        \If{$d\ell < \ \sim U(0, 1)$}{
            $\ell_{t+1} \gets \ell_{t+1} - 1$ \;
        }
        \Return $\ell_{t+1}$ \;
    }
    \textbf{end} \;
    \caption{The algorithmic description for $f: \mathcal{M} \rightarrow \mathcal{M}$.
    To stay consistent with the definition of $f$ we denote $c$ and $d$ as parameters of the model itself.}
    \label{alg:mutateFunction}
\end{algorithm}
